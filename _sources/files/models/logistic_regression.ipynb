{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Load the packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('./../../../../data/train/train.csv')\n",
    "test_df = pd.read_csv('./../../../../data/test/test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load the feature selection result\n",
    "feature_selector = pd.read_csv('./../../../../data/feature_ranking.csv')\n",
    "feature_selector.set_index('Unnamed: 0', inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Separate feature space from target variable\n",
    "y_train = train_df['Attrition']\n",
    "X_train = train_df.drop('Attrition', axis=1)\n",
    "y_test = test_df['Attrition']\n",
    "X_test = test_df.drop('Attrition', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will be running models for different set of features and evaluate their performances. We start with complete dataset and then start with meaximum feature score of 8 to 5."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Declare the model paramters for searching\n",
    "C = np.logspace(-4, 4, num=9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Declare and train the model\n",
    "log_reg = LogisticRegressionCV(Cs=C, scoring='f1', max_iter=1000, n_jobs=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complete data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Train the model\n",
    "log_reg.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03,\n",
       "       1.e+04]),\n",
       "                     max_iter=1000, n_jobs=-1, scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Predict using model\n",
    "y_pred = log_reg.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Make the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.91      0.91       255\n",
      "        True       0.45      0.51      0.48        39\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.69      0.71      0.70       294\n",
      "weighted avg       0.86      0.85      0.86       294\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the above reported, it can be observed that the model is quite good for predicting who won't leave but pretty bad for identifying who will be leaving."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature score of 8"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Create the new dataset\n",
    "\n",
    "# Get features with feature score of 8\n",
    "features = feature_selector[feature_selector['Total']==8].index.tolist()\n",
    "X_train_8 = X_train.loc[:, features]\n",
    "X_test_8 = X_test.loc[:, features]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Train the model\n",
    "log_reg.fit(X_train_8, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03,\n",
       "       1.e+04]),\n",
       "                     max_iter=1000, n_jobs=-1, scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Predict with model\n",
    "y_pred_8 = log_reg.predict(X_test_8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Make the report\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.91      0.91       255\n",
      "        True       0.45      0.51      0.48        39\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.69      0.71      0.70       294\n",
      "weighted avg       0.86      0.85      0.86       294\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is no improvement in the result. But since this model uses less number of features, it better to use it in production in order to improve the retraining and inferencing with huge load of data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the least number of features that could be used gave the same performance as all the features, it is better to skip the other scores since the chance of improvement in result is quite less."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('hra': conda)"
  },
  "interpreter": {
   "hash": "d88894e6c4ebfb1ff377de8b74f40dafb6f3238951903707a6f17b68b3cee000"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}