{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import packages\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from imblearn.over_sampling import SMOTE\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('./../../../data/cleaned_data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load lists of numerical and categorical columns from the static file\n",
    "with open('./../../../data/statics.json') as f:\n",
    "    statics = json.load(f)\n",
    "categorical_columns = statics['categorical_columns']\n",
    "numerical_columns = statics['numerical_columns']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we begin the preprocessing, it is necessary to split the data into training and testing sets. This is necessary because every transformation has to be trainined on training data while transformation should be done on training and testing set. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Separate the target variable from the other data\n",
    "y = df['Attrition']\n",
    "X = df.drop('Attrition', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "categorical_columns.remove('Attrition')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1176, 31)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Seggregate the data into numerical and categorical variable for training data\n",
    "num_df_train = X_train[numerical_columns]\n",
    "cat_df_train = X_train[categorical_columns]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Seggregate the data into numerical and categorical variable for testing data\n",
    "num_df_test = X_test[numerical_columns]\n",
    "cat_df_test = X_test[categorical_columns]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing per data types"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Numerical columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us begin the data preprocessing with the numerical columns. Since some of the columns are positively skewed and they does not belong to the same scale, it would be better to make the their scale common. The transformation that will be used in the MinMaxScaler from the scikit-learn. Mathematically, it can be given as:\n",
    "$$\n",
    "X' = \\frac{X - X_{min}}{X_{max} - X_{min}}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Scale the data\n",
    "transformer = MinMaxScaler()\n",
    "num_df_train = transformer.fit_transform(num_df_train)\n",
    "num_df_test = transformer.transform(num_df_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Convert the numpy arrays to dataframe\n",
    "num_df_train = pd.DataFrame(num_df_train, columns=numerical_columns)\n",
    "num_df_test = pd.DataFrame(num_df_test, columns=numerical_columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Categorical columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As far as categorical columns are concerned, they need to be represented by numbers so that machines can process the data. For our data, some columns need ordinal encoding while others need one-hot encoding."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Separate the columns into ordinal and one hot columns\n",
    "ordinal_columns = ['Education', 'EnvironmentSatisfaction', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'OverTime', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'WorkLifeBalance']\n",
    "one_hot_columns = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "ordinal_list = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to encode columns with some order, we need to first declare which will help the algorithm to encode."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "ordinal_list.append(['Below College', 'College', 'Bachelor', 'Master', 'Doctor']) # Education\n",
    "ordinal_list.append(['Low', 'Medium', 'High', 'Very High']) # EnvironmentSatisfaction\n",
    "ordinal_list.append(['Low', 'Medium', 'High', 'Very High']) # JobInvolvement\n",
    "ordinal_list.append(['level_1', 'level_2', 'level_3', 'level_4', 'level_5']) #JobLevel\n",
    "ordinal_list.append(['Low', 'Medium', 'High', 'Very High']) # JobSatisfaction\n",
    "ordinal_list.append(['No', 'Yes']) # OverTime\n",
    "ordinal_list.append(['Excellent', 'Outstanding']) # PerformanceRating\n",
    "ordinal_list.append(['Low', 'Medium', 'High', 'Very High']) # RelationshipSatisfaction\n",
    "ordinal_list.append(['level_0', 'level_1', 'level_2', 'level_3']) # JobInvolvement\n",
    "ordinal_list.append(['Bad', 'Good', 'Better', 'Best']) # WorkLifeBalance\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Apply Ordinal Encoder\n",
    "onc = OrdinalEncoder(categories=ordinal_list)\n",
    "ordinal_cat_df_train = onc.fit_transform(cat_df_train[ordinal_columns])\n",
    "ordinal_cat_df_test = onc.transform(cat_df_test[ordinal_columns])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Covert the numpy array to dataframe\n",
    "ordinal_cat_df_train = pd.DataFrame(ordinal_cat_df_train, columns=ordinal_columns)\n",
    "ordinal_cat_df_test = pd.DataFrame(ordinal_cat_df_test, columns=ordinal_columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Apply One-hot Encoder\n",
    "onehot_cat_df_train = pd.DataFrame()\n",
    "for column in one_hot_columns:\n",
    "    temp = pd.get_dummies(cat_df_train[column], prefix=column, prefix_sep=' ')\n",
    "    onehot_cat_df_train = pd.concat([onehot_cat_df_train, temp], axis=1)\n",
    "\n",
    "onehot_cat_df_test = pd.DataFrame()\n",
    "for column in one_hot_columns:\n",
    "    temp = pd.get_dummies(cat_df_test[column], prefix=column, prefix_sep=' ')\n",
    "    onehot_cat_df_test = pd.concat([onehot_cat_df_test, temp], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merge preprocessed data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before merging all the data together, it is better to check the length of individual data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Check the length of the training data\n",
    "print(f\"Length of numerical data: {len(num_df_train)}\")\n",
    "print(f\"Length of ordinal categorical data: {len(ordinal_cat_df_train)}\")\n",
    "print(f\"Length of one-hot encoded columns data: {onehot_cat_df_train.shape[0]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length of numerical data: 1176\n",
      "Length of ordinal categorical data: 1176\n",
      "Length of one-hot encoded columns data: 1176\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Check the length of the testing data\n",
    "print(f\"Length of numerical data: {len(num_df_test)}\")\n",
    "print(f\"Length of ordinal categorical data: {len(ordinal_cat_df_test)}\")\n",
    "print(f\"Length of one-hot encoded columns data: {onehot_cat_df_test.shape[0]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Length of numerical data: 294\n",
      "Length of ordinal categorical data: 294\n",
      "Length of one-hot encoded columns data: 294\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since all the length match together, the data can be merged together."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Merge the data\n",
    "train_df = pd.concat([num_df_train.reset_index(drop=True), ordinal_cat_df_train.reset_index(drop=True), onehot_cat_df_train.reset_index(drop=True)], axis=1)\n",
    "test_df = pd.concat([num_df_test.reset_index(drop=True), ordinal_cat_df_test.reset_index(drop=True), onehot_cat_df_test.reset_index(drop=True)], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking upon the final shape of both the dataframes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "print(f\"The shape of training data is: {train_df.shape}\")\n",
    "print(f\"The shape of testing data is: {test_df.shape}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The shape of training data is: (1176, 51)\n",
      "The shape of testing data is: (294, 51)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Handling Outliers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Outliers are the observations which does not fit well with the dataset. These observations are errors during the recording process. Outliers does not find place in the pattern that exist in the dataset and hence in order to reduce their influence on the outcome it is better to either treat them or remove them. Since we cannot correct the values of such data now, we will be resorting to remove them."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To remove outliers, it is necessary to detect them first. We will be utilizing various methods to detect the outliers and then combine the results of those methods to get the final set for removal. There will be 3 methods that will be used - \n",
    "1. Robust Covariance\n",
    "2. Isolation Forest\n",
    "3. Local Outlier Factor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Initialize the algorithms\n",
    "rob_cov = EllipticEnvelope(contamination=0.05)\n",
    "iso_fst = IsolationForest(contamination=0.05, random_state=42)\n",
    "lof = LocalOutlierFactor(contamination=0.05)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Find the outliers using each method\n",
    "y_pred_rob_cov = rob_cov.fit_predict(train_df)\n",
    "y_pred_iso_fst = iso_fst.fit_predict(train_df)\n",
    "y_pred_lof = lof.fit_predict(train_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/pushkar/miniforge3/envs/hra/lib/python3.8/site-packages/sklearn/covariance/_robust_covariance.py:647: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\"The covariance matrix associated to your dataset \"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Create a dataframe for the result\n",
    "y_pred_df = pd.DataFrame(columns = ['Robust Covariance', 'Isolation Forest', 'Local Outlier Factor'])\n",
    "y_pred_df['Robust Covariance'] = y_pred_rob_cov\n",
    "y_pred_df['Isolation Forest'] = y_pred_iso_fst\n",
    "y_pred_df['Local Outlier Factor'] = y_pred_lof"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Find the indexes of observations for which are marked as outlier by majority of algorithm\n",
    "y_pred_df['Total'] = y_pred_df['Robust Covariance'] + y_pred_df['Isolation Forest'] + y_pred_df['Local Outlier Factor']\n",
    "y_pred_df['Outlier'] = y_pred_df['Total'].apply(lambda x: True if x < 0 else False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "print(f\"Total outliers detected: {len(y_pred_df[y_pred_df['Outlier'] == True])}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total outliers detected: 38\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the total outliers detected are very few, it would be safe for us to remove them. Though we lose information after removing the outliers but that will not harm our results to greater extent."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Remove outliers from the training data\n",
    "outleir_index = y_pred_df[y_pred_df['Outlier'] == True].index\n",
    "train_df = train_df.drop(outleir_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "y_train = y_train.reset_index(drop=True).drop(labels=outleir_index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Oversampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The target variable is significant class imbalance which may introduce bias during the training process. In order to avoid such situation it is necessary to undersample the majority class or oversmaple the minority class of the target variable. But undersampling may lead to data loss and since we don't have much data in the first place, it will be better to perform oversampling of the minority class."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Convert the yes and no to binary values\n",
    "y_train = y_train.apply(lambda x: True if x=='Yes' else False)\n",
    "y_test = y_test.apply(lambda x: True if x=='Yes' else False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Perform oversampling\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(train_df, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Store the values in files\n",
    "X_train = pd.concat([X_train, y_train], axis=1)\n",
    "X_test = pd.concat([test_df.reset_index(drop=True), y_test.reset_index(drop=True)], axis=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "X_train.to_csv('./../../../data/train/train.csv', index=False)\n",
    "X_test.to_csv('./../../../data/test/test.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('hra': conda)"
  },
  "interpreter": {
   "hash": "d88894e6c4ebfb1ff377de8b74f40dafb6f3238951903707a6f17b68b3cee000"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}