{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load the packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('./../../../../data/train/train.csv')\n",
    "test_df = pd.read_csv('./../../../../data/test/test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Load the feature selection result\n",
    "feature_selector = pd.read_csv('./../../../../data/feature_ranking.csv')\n",
    "feature_selector.set_index('Unnamed: 0', inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Separate feature space from target variable\n",
    "y_train = train_df['Attrition']\n",
    "X_train = train_df.drop('Attrition', axis=1)\n",
    "y_test = test_df['Attrition']\n",
    "X_test = test_df.drop('Attrition', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will be running models for different set of features and evaluate their performances. We start with complete dataset and then start with meaximum feature score of 8 to 5."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Declare the model paramters for searching\n",
    "param_grid = dict(\n",
    "    criterion = ['gini', 'entropy'],\n",
    "    splitter = ['best', 'random'],\n",
    "    max_depth = [20, 40, 60, None],\n",
    "    min_samples_split = [2, 10, 40]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Declare and train the model\n",
    "dt_clf = DecisionTreeClassifier(class_weight=\"balanced\", max_features=None)\n",
    "dt = GridSearchCV(estimator=dt_clf, param_grid=param_grid, scoring='f1', n_jobs=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complete data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Train the model\n",
    "dt.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(class_weight='balanced'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [20, 40, 60, None],\n",
       "                         'min_samples_split': [2, 10, 40],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Get the parameters for the best model\n",
    "dt.best_estimator_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       max_depth=40)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Predict using model\n",
    "y_pred = dt.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Make the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.85      0.87       255\n",
      "        True       0.21      0.26      0.23        39\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.55      0.56      0.55       294\n",
      "weighted avg       0.79      0.78      0.78       294\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The results not better than that of logistic regression. The precision, recall and f1 of attrition is not at all good as that of random forest."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature score of 8"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Create the new dataset\n",
    "\n",
    "# Get features with feature score of 8\n",
    "features = feature_selector[feature_selector['Total']==8].index.tolist()\n",
    "X_train_8 = X_train.loc[:, features]\n",
    "X_test_8 = X_test.loc[:, features]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Train the model\n",
    "dt.fit(X_train_8, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(class_weight='balanced'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [20, 40, 60, None],\n",
       "                         'min_samples_split': [2, 10, 40],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='f1')"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Predict with model\n",
    "y_pred_8 = dt.predict(X_test_8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Make the report\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.85      0.87       255\n",
      "        True       0.21      0.26      0.23        39\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.55      0.56      0.55       294\n",
      "weighted avg       0.79      0.78      0.78       294\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is no improvement in the result. But since this model uses less number of features, it better to use it in production in order to improve the retraining and inferencing with huge load of data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the least number of features that could be used gave the same performance as all the features, it is better to skip the other scores since the chance of improvement in result is quite less."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('hra': conda)"
  },
  "interpreter": {
   "hash": "d88894e6c4ebfb1ff377de8b74f40dafb6f3238951903707a6f17b68b3cee000"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}